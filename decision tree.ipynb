{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_csv(r\"C:\\Users\\David gathara marigi\\Downloads\\loan_data_sample.csv\", index_col = \"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.copy() \n",
    "numeric_df['NAME_CONTRACT_TYPE'] = numeric_df['NAME_CONTRACT_TYPE'].map({'Cash loans': 0, 'Revolving loans': 1}) \n",
    "numeric_df['CODE_GENDER'] = numeric_df['CODE_GENDER'].map({'M': 0, 'F': 1}) \n",
    "numeric_df['FLAG_OWN_CAR'] = numeric_df['FLAG_OWN_CAR'].map({'N': 0, 'Y': 1}) \n",
    "numeric_df['FLAG_OWN_REALTY'] = numeric_df['FLAG_OWN_REALTY'].map({'N': 0, 'Y': 1}) \n",
    "numeric_df['NAME_EDUCATION_TYPE'] = numeric_df['NAME_EDUCATION_TYPE'].map({'Lower secondary': 0, 'Secondary / secondary special': 0, \n",
    "                                       'Incomplete higher': 1, \n",
    "                                       'Higher education': 2, \n",
    "                                       'Academic degree': 2}) \n",
    "numeric_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df.info() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = numeric_df.drop('TARGET', axis=1) \n",
    "targets = numeric_df['TARGET'] \n",
    "x_train, x_test, y_train, y_test = train_test_split(features, \n",
    "                                                    targets, \n",
    "stratify=targets, \n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier() \n",
    "dt.fit(x_train, y_train) \n",
    "print(f'Train accuracy: {dt.score(x_train, y_train)}')  \n",
    "print(f'Test accuracy: {dt.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dt = DecisionTreeClassifier(max_depth=2, \n",
    "max_features=None) \n",
    "small_dt.fit(x_train, y_train) \n",
    "print(f'Train accuracy: {small_dt.score(x_train, y_train)}') \n",
    "print(f'Test accuracy: {small_dt.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 12)) \n",
    "_ = plot_tree(small_dt, feature_names=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(max_depth=10, n_jobs=-1, \n",
    "random_state=42) \n",
    "rfc.fit(x_train, y_train) \n",
    "print(rfc.score(x_train, y_train)) \n",
    "print(rfc.score(x_test, y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_sample = x_train.sample(1000) \n",
    "y_tr_sample = y_train.loc[x_tr_sample.index] \n",
    "params = {'n_estimators': [100, 300, 500], \n",
    "'max_depth': [10, 15, 20], \n",
    "'max_features': [3, 6, 9], \n",
    "'random_state': [42], \n",
    "'n_jobs': [-1]} \n",
    "gs = GridSearchCV(rfc, param_grid=params, n_jobs=-1) \n",
    "gs.fit(x_tr_sample, y_tr_sample) \n",
    "print(gs.best_estimator_) \n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o \n",
    "h2o.init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h2o.H2OFrame(df) \n",
    "hf['TARGET'] = hf['TARGET'].asfactor() \n",
    "train, valid = hf.split_frame(ratios=[.8], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from h2o.estimators import H2ORandomForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drf = H2ORandomForestEstimator(ntrees=100, max_depth=10, \n",
    "mtries=3) \n",
    "feature_columns = hf.columns\n",
    "feature_columns.remove('TARGET') \n",
    "target_column = 'TARGET' \n",
    "drf.train(x=feature_columns, \n",
    "          y=target_column, \n",
    "          training_frame=train, \n",
    "          validation_frame=valid) \n",
    "drf.model_performance(valid).F1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = drf.predict(train) \n",
    "(predictions['p1'] > 0.097).as_data_frame()['p1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = h2o.save_model(model=drf, path='drf', force=True) \n",
    "drf2 = h2o.load_model(path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drf.varimp()\n",
    "drf.varimp_plot(server=True)\n",
    "plt.savefig() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.model_selection import feature_importances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = feature_importances(gs.best_estimator_, \n",
    "                        x_train, \n",
    "                        y_train, \n",
    "                        colors=['darkblue'] * \n",
    "features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier \n",
    "adaboost = AdaBoostClassifier(n_estimators=100, \n",
    "                              learning_rate=0.5, \n",
    "                              random_state=42) \n",
    "adaboost.fit(x_train, y_train) \n",
    "print(adaboost.score(x_train, y_train)) \n",
    "print(adaboost.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import setup, create_model, tune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = setup(data=numeric_df, target='TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = create_model('ada', fold=3) \n",
    "tuned_adaboost, gridsearch = tune_model(adaboost, fold=3, \n",
    "return_tuner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" XGBoost with PyCaret\n",
    " Again, we can use \n",
    "xgboost easily through \n",
    "pycaret , which, by default,\n",
    " searches the following hyperparameter space:\n",
    " learning_rate : 0.0000001 to 0.5\n",
    " n_estmators : 10-300 in steps of 10\n",
    " subsample : 0.2 to 1\n",
    " max_depth : 1 to 11 in steps of 1\n",
    " colsample_bytree : 0.5 to 1\n",
    " min_child_weight : 1 to 4 in steps of 1\n",
    " reg_alpha : 0.0000001 to 10\n",
    " reg_lambda : 0.0000001 to 10\n",
    " scale_pos_weight : 0 to 50 in steps of 0.1\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_distributions = {\"learning_rate\": UniformDistribution(0.000001, 0.5, log=True), \n",
    "\"n_estimators\": IntUniformDistribution(10, 300), \n",
    "\"subsample\": UniformDistribution(0.2, 1), \n",
    "\"max_depth\": IntUniformDistribution(1, 11), \n",
    "\"colsample_bytree\": UniformDistribution(0.5, 1), \n",
    "\"min_child_weight\": IntUniformDistribution(1, 4), \n",
    "\"reg_alpha\": UniformDistribution(0.0000000001, 10, \n",
    "log=True), \n",
    "    \"reg_lambda\": UniformDistribution(0.0000000001, 10, \n",
    "log=True), \n",
    "    \"scale_pos_weight\": UniformDistribution(1, 50), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = create_model('xgboost', fold=3) \n",
    "best_xgb, tuner = tune_model(xgb, \n",
    "                             fold=3, \n",
    "                             search_library='scikit-optimize', \n",
    "                             return_tuner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb.get_params() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.cv_results_['params']\n",
    "tuner.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.get_booster().get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb.feature_importances_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(x_train, label=y_train) \n",
    "dtest = xgb.DMatrix(x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.train(params={'objective': 'binary:logistic'}, \n",
    "dtrain=dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = xgb_model.predict(dtrain) \n",
    "test_preds = xgb_model.predict(dtest) \n",
    "print(accuracy_score(y_train, train_preds > 0.5)) \n",
    "print(accuracy_score(y_test, test_preds > 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = xgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_gpu = create_model('xgboost', \n",
    "                           fold=3, \n",
    "                           tree_method='gpu_hist', \n",
    "                           gpu_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_gbm = create_model('lightgbm', fold=3) \n",
    "best_lgbm, tuner = tune_model(light_gbm, \n",
    "                              fold=3, \n",
    "                              search_library='scikit optimize', \n",
    "                              return_tuner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm.plot_importance(best_lgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model = lightgbm.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_lgb = lgb_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = create_model('catboost', fold=3) \n",
    "best_cb, tuner = tune_model(catboost_model, \n",
    "                            fold=3, \n",
    "                            search_library='scikit-optimize', \n",
    "                            return_tuner=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model = CatBoostClassifier() \n",
    "catboost_train_data = Pool(x_train,  \n",
    "                           y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.fit(catboost_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_model.score(catboost_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_test_data = Pool(x_test) \n",
    "cb_model.predict(catboost_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cb = catboost.CatBoostClassifier(**best_cb.get_params()) \n",
    "new_cb.set_params(n_estimators=1000) \n",
    "new_cb.fit(X=x_train, \n",
    "           y=y_train, \n",
    "           eval_set=(x_test, y_test), \n",
    "           early_stopping_rounds=10, \n",
    "           plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
